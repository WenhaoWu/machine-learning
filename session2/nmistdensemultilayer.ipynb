{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.3\n",
      "1.4.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "print(keras.__version__)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11cf4d828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "img1 = x_train[314].reshape(-1, 28*28).astype('float32') / 255.0\n",
    "img1label = y_train[314]\n",
    "\n",
    "plt.imshow(img1.reshape(28,28), cmap=plt.cm.binary)\n",
    "plt.show()\n",
    "print(img1label)\n",
    "\n",
    "x_train = x_train.reshape(-1, 28 * 28).astype('float32') / 255.0\n",
    "x_test = x_test.reshape(-1, 28 * 28).astype('float32') / 255.0\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train)\n",
    "y_test = keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 25)                1275      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 25)                650       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                260       \n",
      "=================================================================\n",
      "Total params: 88,285\n",
      "Trainable params: 88,285\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(100, input_shape=(28 * 28,), activation='relu'))\n",
    "model.add(keras.layers.Dense(50, activation='relu'))\n",
    "model.add(keras.layers.Dense(50, activation='relu'))\n",
    "model.add(keras.layers.Dense(25, activation='relu'))\n",
    "model.add(keras.layers.Dense(25, activation='relu'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/60\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 1.5437 - acc: 0.4843 - val_loss: 0.7104 - val_acc: 0.7876\n",
      "Epoch 2/60\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.4943 - acc: 0.8556 - val_loss: 0.3604 - val_acc: 0.8938\n",
      "Epoch 3/60\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.3123 - acc: 0.9099 - val_loss: 0.2714 - val_acc: 0.9177\n",
      "Epoch 4/60\n",
      "60000/60000 [==============================] - 5s 75us/step - loss: 0.2452 - acc: 0.9282 - val_loss: 0.2472 - val_acc: 0.9256\n",
      "Epoch 5/60\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.2060 - acc: 0.9392 - val_loss: 0.2104 - val_acc: 0.9360\n",
      "Epoch 6/60\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.1794 - acc: 0.9474 - val_loss: 0.1717 - val_acc: 0.9497\n",
      "Epoch 7/60\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.1603 - acc: 0.9528 - val_loss: 0.1546 - val_acc: 0.9559\n",
      "Epoch 8/60\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1441 - acc: 0.9580 - val_loss: 0.1508 - val_acc: 0.9543\n",
      "Epoch 9/60\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1307 - acc: 0.9619 - val_loss: 0.1396 - val_acc: 0.9596\n",
      "Epoch 10/60\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1204 - acc: 0.9645 - val_loss: 0.1307 - val_acc: 0.9608\n",
      "Epoch 11/60\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.1114 - acc: 0.9669 - val_loss: 0.1238 - val_acc: 0.9643\n",
      "Epoch 12/60\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.1027 - acc: 0.9694 - val_loss: 0.1221 - val_acc: 0.9631\n",
      "Epoch 13/60\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.0945 - acc: 0.9719 - val_loss: 0.1356 - val_acc: 0.9589\n",
      "Epoch 14/60\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.0893 - acc: 0.9731 - val_loss: 0.1117 - val_acc: 0.9658\n",
      "Epoch 15/60\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.0833 - acc: 0.9755 - val_loss: 0.1194 - val_acc: 0.9644\n",
      "Epoch 16/60\n",
      "60000/60000 [==============================] - 5s 75us/step - loss: 0.0779 - acc: 0.9762 - val_loss: 0.1122 - val_acc: 0.9654\n",
      "Epoch 17/60\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.0725 - acc: 0.9785 - val_loss: 0.1056 - val_acc: 0.9685\n",
      "Epoch 18/60\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 0.0686 - acc: 0.9796 - val_loss: 0.1090 - val_acc: 0.9657\n",
      "Epoch 19/60\n",
      "60000/60000 [==============================] - 5s 83us/step - loss: 0.0652 - acc: 0.9802 - val_loss: 0.1065 - val_acc: 0.9697\n",
      "Epoch 20/60\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.0600 - acc: 0.9822 - val_loss: 0.1178 - val_acc: 0.9646\n",
      "Epoch 21/60\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.0568 - acc: 0.9835 - val_loss: 0.1062 - val_acc: 0.9682\n",
      "Epoch 22/60\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.0533 - acc: 0.9838 - val_loss: 0.1014 - val_acc: 0.9708\n",
      "Epoch 23/60\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.0501 - acc: 0.9855 - val_loss: 0.1030 - val_acc: 0.9696\n",
      "Epoch 24/60\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.0471 - acc: 0.9857 - val_loss: 0.1215 - val_acc: 0.9661\n",
      "Epoch 25/60\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 0.0442 - acc: 0.9871 - val_loss: 0.1079 - val_acc: 0.9697\n",
      "Epoch 26/60\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.0419 - acc: 0.9880 - val_loss: 0.1073 - val_acc: 0.9693\n",
      "Epoch 27/60\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 0.0393 - acc: 0.9889 - val_loss: 0.0993 - val_acc: 0.9724\n",
      "Epoch 28/60\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.0365 - acc: 0.9896 - val_loss: 0.1059 - val_acc: 0.9701\n",
      "Epoch 29/60\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.0340 - acc: 0.9904 - val_loss: 0.1049 - val_acc: 0.9706\n",
      "Epoch 30/60\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.0324 - acc: 0.9906 - val_loss: 0.1494 - val_acc: 0.9614\n",
      "Epoch 31/60\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.0307 - acc: 0.9915 - val_loss: 0.1088 - val_acc: 0.9694\n",
      "Epoch 32/60\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 0.0289 - acc: 0.9915 - val_loss: 0.1039 - val_acc: 0.9704\n",
      "Epoch 33/60\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.0266 - acc: 0.9924 - val_loss: 0.1211 - val_acc: 0.9682\n",
      "Epoch 34/60\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 0.0250 - acc: 0.9930 - val_loss: 0.1308 - val_acc: 0.9668\n",
      "Epoch 35/60\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.0236 - acc: 0.9936 - val_loss: 0.1088 - val_acc: 0.9701\n",
      "Epoch 36/60\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.0217 - acc: 0.9945 - val_loss: 0.1116 - val_acc: 0.9686\n",
      "Epoch 37/60\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.0208 - acc: 0.9944 - val_loss: 0.1112 - val_acc: 0.9713\n",
      "Epoch 38/60\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.0197 - acc: 0.9947 - val_loss: 0.1108 - val_acc: 0.9709\n",
      "Epoch 39/60\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.0175 - acc: 0.9957 - val_loss: 0.1221 - val_acc: 0.9694\n",
      "Epoch 40/60\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.0172 - acc: 0.9952 - val_loss: 0.1156 - val_acc: 0.9696\n",
      "Epoch 41/60\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.0157 - acc: 0.9960 - val_loss: 0.1153 - val_acc: 0.9717\n",
      "Epoch 42/60\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.0142 - acc: 0.9968 - val_loss: 0.1257 - val_acc: 0.9693\n",
      "Epoch 43/60\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.0129 - acc: 0.9971 - val_loss: 0.1162 - val_acc: 0.9712\n",
      "Epoch 44/60\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.0118 - acc: 0.9975 - val_loss: 0.1173 - val_acc: 0.9708\n",
      "Epoch 45/60\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.0113 - acc: 0.9975 - val_loss: 0.1173 - val_acc: 0.9712\n",
      "Epoch 46/60\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.0103 - acc: 0.9978 - val_loss: 0.1333 - val_acc: 0.9674\n",
      "Epoch 47/60\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.0093 - acc: 0.9982 - val_loss: 0.1299 - val_acc: 0.9694\n",
      "Epoch 48/60\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.0090 - acc: 0.9983 - val_loss: 0.1230 - val_acc: 0.9706\n",
      "Epoch 49/60\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.0073 - acc: 0.9989 - val_loss: 0.1223 - val_acc: 0.9718\n",
      "Epoch 50/60\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.0068 - acc: 0.9989 - val_loss: 0.1482 - val_acc: 0.9669\n",
      "Epoch 51/60\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.0070 - acc: 0.9989 - val_loss: 0.1262 - val_acc: 0.9722\n",
      "Epoch 52/60\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.0062 - acc: 0.9992 - val_loss: 0.1333 - val_acc: 0.9703\n",
      "Epoch 53/60\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.0053 - acc: 0.9993 - val_loss: 0.1357 - val_acc: 0.9705\n",
      "Epoch 54/60\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.0056 - acc: 0.9992 - val_loss: 0.1308 - val_acc: 0.9712\n",
      "Epoch 55/60\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.0044 - acc: 0.9996 - val_loss: 0.1303 - val_acc: 0.9720\n",
      "Epoch 56/60\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.0050 - acc: 0.9991 - val_loss: 0.1343 - val_acc: 0.9706\n",
      "Epoch 57/60\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.0040 - acc: 0.9997 - val_loss: 0.1367 - val_acc: 0.9705\n",
      "Epoch 58/60\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.0035 - acc: 0.9997 - val_loss: 0.1355 - val_acc: 0.9718\n",
      "Epoch 59/60\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 0.0035 - acc: 0.9997 - val_loss: 0.1385 - val_acc: 0.9718\n",
      "Epoch 60/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40960/60000 [===================>..........] - ETA: 1s - loss: 0.0035 - acc: 0.9997"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "hist = model.fit(x_train, y_train, epochs=60, batch_size=64, validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = hist.history['acc']\n",
    "val_acc = hist.history['val_acc']\n",
    "loss = hist.history['loss']\n",
    "val_loss = hist.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
