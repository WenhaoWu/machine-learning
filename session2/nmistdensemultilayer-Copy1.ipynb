{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(-1, 28 * 28).astype('float32') / 255.0\n",
    "x_test = x_test.reshape(-1, 28 * 28).astype('float32') / 255.0\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train)\n",
    "y_test = keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_61 (Dense)             (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 25)                1275      \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 25)                650       \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 10)                260       \n",
      "=================================================================\n",
      "Total params: 88,285\n",
      "Trainable params: 88,285\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(100, input_shape=(28 * 28,), activation='relu'))\n",
    "model.add(keras.layers.Dense(50, activation='relu'))\n",
    "model.add(keras.layers.Dense(50, activation='relu'))\n",
    "model.add(keras.layers.Dense(25, activation='relu'))\n",
    "model.add(keras.layers.Dense(25, activation='relu'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 1.2765 - acc: 0.5944 - val_loss: 0.4845 - val_acc: 0.8486\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.3783 - acc: 0.8905 - val_loss: 0.3003 - val_acc: 0.9146\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.2795 - acc: 0.9191 - val_loss: 0.2383 - val_acc: 0.9324\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.2218 - acc: 0.9357 - val_loss: 0.1996 - val_acc: 0.9415\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.1871 - acc: 0.9454 - val_loss: 0.1696 - val_acc: 0.9498\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.1618 - acc: 0.9526 - val_loss: 0.1561 - val_acc: 0.9527\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.1437 - acc: 0.9575 - val_loss: 0.1407 - val_acc: 0.9575\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.1296 - acc: 0.9616 - val_loss: 0.1403 - val_acc: 0.9584\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.1174 - acc: 0.9659 - val_loss: 0.1292 - val_acc: 0.9613\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.1077 - acc: 0.9688 - val_loss: 0.1247 - val_acc: 0.9632\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.0996 - acc: 0.9704 - val_loss: 0.1133 - val_acc: 0.9660\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.0929 - acc: 0.9728 - val_loss: 0.1249 - val_acc: 0.9615\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.0862 - acc: 0.9747 - val_loss: 0.1140 - val_acc: 0.9657\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.0797 - acc: 0.9770 - val_loss: 0.1047 - val_acc: 0.9679\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.0756 - acc: 0.9779 - val_loss: 0.1027 - val_acc: 0.9691\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.0709 - acc: 0.9789 - val_loss: 0.1023 - val_acc: 0.9688\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.0652 - acc: 0.9806 - val_loss: 0.1039 - val_acc: 0.9687\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.0617 - acc: 0.9820 - val_loss: 0.1562 - val_acc: 0.9532\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.0584 - acc: 0.9833 - val_loss: 0.0977 - val_acc: 0.9696\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.0545 - acc: 0.9842 - val_loss: 0.0920 - val_acc: 0.9711\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "hist = model.fit(x_train, y_train, epochs=20, batch_size=64, validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 2 1 0 4 1 4 9 8 9 0 6 9 0 1 5 9 7 3 4]\n",
      "[7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4]\n",
      "\n",
      "Accurancy:  0.95\n"
     ]
    }
   ],
   "source": [
    "x_pred_test = x_test[:20]\n",
    "y_pred_label = y_test[:20]\n",
    "\n",
    "preds = model.predict(x_pred_test)\n",
    "\n",
    "pred = []\n",
    "for x in range(0,len(preds)):\n",
    "    maxIndex = np.argmax(preds[x])\n",
    "    pred.append(maxIndex)\n",
    "\n",
    "pred_label = []\n",
    "for x in range(0,len(y_pred_label)):\n",
    "    maxIndex = np.argmax(y_pred_label[x])\n",
    "    pred_label.append(maxIndex)\n",
    "\n",
    "arr_pred = np.array(pred)\n",
    "arr_pred_label = np.array(pred_label)\n",
    "print(arr_pred)\n",
    "print(arr_pred_label)\n",
    "print(\"\\nAccurancy: \",np.sum(arr_pred == arr_pred_label) / len(arr_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above cell is to use the test data set to verify the caluclation of accurancy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1294e69e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 2 3 2]\n",
      "[1 7 3 7 2 6 1 8 9 0 1 7 7 9 8 3 5 4 4 9]\n",
      "\n",
      "Accurancy:  0.1\n"
     ]
    }
   ],
   "source": [
    "#https://stackoverflow.com/a/12201744/3628117\n",
    "#The img.convert('L') doesnot produce array with shape()\n",
    "def rgb2gray(rgb):\n",
    "    return np.dot(rgb[...,:3], [0.299, 0.587, 0.114])\n",
    "\n",
    "imgs = np.zeros(shape=(20,784))\n",
    "for x in range(1,21):\n",
    "    img = keras.preprocessing.image.load_img(path='./handwrite/{0}.png'.format(x), target_size=(28,28)) #Set target size with tuple\n",
    "    gray = rgb2gray(np.array(img)) #Conver the rgb file to greyscale\n",
    "    arr = np.array(gray)\n",
    "    arr = arr.astype('float32') / 255.0\n",
    "    arr = arr.reshape(-1, 28*28)\n",
    "    imgs[x-1] = arr\n",
    "\n",
    "plt.imshow(imgs[0].reshape(28,28), cmap = plt.get_cmap('gray'))\n",
    "plt.show()\n",
    "   \n",
    "labels = np.array([1,7,3,7,2,6,1,8,9,0,1,7,7,9,8,3,5,4,4,9])\n",
    "\n",
    "preds = model.predict(imgs)\n",
    "\n",
    "pred = []\n",
    "for x in range(0,len(preds)):\n",
    "    maxIndex = np.argmax(preds[x])\n",
    "    pred.append(maxIndex)\n",
    "\n",
    "arr_pred = np.array(pred)\n",
    "arr_pred_label = np.array(labels)\n",
    "print(arr_pred)\n",
    "print(arr_pred_label)\n",
    "print(\"\\nAccurancy: \",np.sum(arr_pred == arr_pred_label) / len(arr_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array([1,7,3,7,2,6,1,8,9,0,1,7,7,9,8,3,5,4,4,9])\n",
    "labels = np.array([1,2,3,4,5,6,7,8,9,0,1,2,3,4,5,6,7,8,9,0])\n",
    "\n",
    "plt.imshow(img, cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
